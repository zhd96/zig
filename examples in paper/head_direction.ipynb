{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load packages\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import sys\n",
    "sys.path.append('../code/');\n",
    "\n",
    "import encoding as enc\n",
    "import decoding as dec\n",
    "import util_plot as uplot\n",
    "\n",
    "seed = 888;\n",
    "np.random.seed(seed) # fix randomness\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deconvolution in matlab (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load('../data/ADN29081-Z_20_10_2018/ms_ADN29081-Z_20_10_2018.mat');\n",
    "c = ms.RawTraces;\n",
    "shape = size(c);\n",
    "K = shape(2);\n",
    "T = shape(1);\n",
    "cd = zeros(K,T);\n",
    "s = zeros(K,T);\n",
    "bs = zeros(K,1);\n",
    "pars = zeros(K,1);\n",
    "sn = zeros(K,1);\n",
    "for n = 1:K\n",
    "    [cd(n,:), s(n,:), options] = deconvolveCa(c(:,n), 'foopsi', 'ar1', 'smin', 0, 'optimize_pars', false, 'pars', 0.95, 'optimize_b', true);\n",
    "    bs(n,1) = options.b;\n",
    "    pars(n,1) = options.pars;\n",
    "    sn(n,1) = options.sn;\n",
    "end\n",
    "save(\"../data/ADN29081-Z_20_10_2018/s_0_deconv.mat\", 'cd', 's', 'bs', 'pars', 'sn');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load deconvolved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load deconvolved data (do deconvolution in matlab using hard-threshold method, set smin=0)\n",
    "deconv = sio.loadmat(\"../data/ADN29081-Z_20_10_2018/s_0_deconv.mat\")\n",
    "hd = sio.loadmat(\"../data/ADN29081-Z_20_10_2018/HD_180_deg_ADN29081-Z_20_10_2018.mat\")['HD_180_deg_total'];\n",
    "frame_map = sio.loadmat(\"../data/ADN29081-Z_20_10_2018/frameMap_ADN29081-Z_20_10_2018.mat\")[\"frameMap\"]\n",
    "Y_real = (deconv[\"s\"]/deconv[\"sn\"]).T;\n",
    "hd = hd[0,frame_map[:,0]-1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## result saving path\n",
    "path = './hd_rlt/';\n",
    "\n",
    "## encoding params\n",
    "n_epochs = 1800; # number of epochs \n",
    "learning_rate = 1e-2; # step size \n",
    "gen_nodes = 30; # number of nodes used in hidden layers\n",
    "\n",
    "thresh = 0; # threshold for bernoulli model\n",
    "gam_shift = 1e-4; # shift for gamma model, in general take it as a small number\n",
    "factor = np.ones(Y_real.shape[1])*thresh; # location parameter for zig model\n",
    "\n",
    "## decoding params\n",
    "bin_len = 181; # number of bins used for bayesian decoding analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ramdomly split data\n",
    "Y_split = np.array_split(Y_real, 92, axis=0);\n",
    "hd_split = np.array_split(hd, 92, axis=0);\n",
    "\n",
    "np.random.seed(seed);\n",
    "perm = np.random.permutation(92);\n",
    "\n",
    "Y_train = [Y_split[index] for index in perm[:56]]\n",
    "Y_train = np.concatenate(Y_train, axis=0)\n",
    "hd_train = [hd_split[index] for index in perm[:56]]\n",
    "hd_train = np.concatenate(hd_train, axis=0)\n",
    "\n",
    "Y_valid = [Y_split[index] for index in perm[56:74]]\n",
    "Y_valid = np.concatenate(Y_valid, axis=0)\n",
    "hd_valid = [hd_split[index] for index in perm[56:74]]\n",
    "hd_valid = np.concatenate(hd_valid, axis=0)\n",
    "\n",
    "Y_test = [Y_split[index] for index in perm[74:]]\n",
    "Y_test = np.concatenate(Y_test, axis=0)\n",
    "hd_test = [hd_split[index] for index in perm[74:]]\n",
    "hd_test = np.concatenate(hd_test, axis=0)\n",
    "\n",
    "nTrain = Y_train.shape[0];\n",
    "nValid = Y_valid.shape[0];\n",
    "nTest = Y_real.shape[0]-nTrain-nValid;\n",
    "\n",
    "Y_const = np.concatenate([Y_split[index] for index in perm], axis=0);\n",
    "hd_const = np.concatenate([hd_split[index] for index in perm], axis=0);\n",
    "\n",
    "hd_bins_use = np.linspace(-180,180,bin_len)[1:];\n",
    "hd_temp = uplot.getBins(hd, hd_bins_use);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train encoding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## poisson\n",
    "spl_values_poi,yfit_poi,cost_poi,test_cost_poi=enc.poissonRunner(Y_train,Y_valid,hd_train,hd_valid,hd_test,n_epochs=n_epochs,learning_rate=learning_rate,gen_nodes=gen_nodes,bin_len=bin_len,path=path);\n",
    "\n",
    "## bernoulli\n",
    "spl_values_ber, yfit_ber, cost_ber, test_cost_ber = enc.bernoulliRunner(Y_train,Y_valid,hd_train,hd_valid,hd_test, thresh=thresh,n_epochs=n_epochs,learning_rate=learning_rate,gen_nodes=gen_nodes,bin_len=bin_len,path=path);\n",
    "\n",
    "## gamma\n",
    "spl_values_gam,spl_k_values_gam,spl_theta_values_gam,yfit_gam,gam_k,gam_theta,cost_gam,test_cost_gam=enc.gammaRunner(Y_train,Y_valid,hd_train,hd_valid,hd_test,factor=gam_shift,n_epochs=n_epochs,learning_rate=learning_rate,gen_nodes=gen_nodes,bin_len=bin_len,path=path);\n",
    "\n",
    "## zig\n",
    "spl_values_zig, spl_p_values_zig, spl_theta_values_zig, zig_k, zig_loc, yfit_zig, zig_p, zig_theta, cost_zig, test_cost_zig = enc.sngRlxRunner(Y_train, Y_valid, hd_train,hd_valid, hd_test, factor, n_epochs=n_epochs,learning_rate=5e-3, gen_nodes=gen_nodes,bin_len=bin_len,path=path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bayesian decoding analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## poisson\n",
    "poi_mean_decode, poi_decode, poi_lik_mat = dec.poissonDecoding(Y_const, spl_values_poi, bin_len=bin_len);\n",
    "\n",
    "## bernoulli\n",
    "ber_mean_decode, ber_decode, ber_lik_mat = dec.bernoulliDecoding(Y_const, thresh, spl_values_ber, bin_len=bin_len);\n",
    "\n",
    "## gamma\n",
    "gam_mean_decode,gam_decode,gam_lik_mat=dec.gammaDecoding(Y_const,spl_k_values_gam,spl_theta_values_gam,factor=gam_shift,bin_len=bin_len);\n",
    "\n",
    "## zig\n",
    "zig_mean_decode, zig_decode, zig_lik_mat = dec.sngRlxDecoding(Y_const, spl_theta_values_zig, \n",
    "                                                           spl_p_values_zig, zig_k, zig_loc, bin_len=bin_len);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check encoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample data\n",
    "y_poisson, p_poi = enc.samplePoisson(yfit_poi, seed=seed);\n",
    "y_bernoulli = enc.sampleBernoulli(yfit_ber, seed=seed);\n",
    "y_zig = enc.sampleSngRlx(zig_p, zig_k, zig_theta, zig_loc, seed=seed);\n",
    "y_gamma = enc.sampleGamma(gam_k, gam_theta, seed=seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted vs observed mean\n",
    "fig_rate = uplot.plotSampleRatem(Y_const, hd_const, y_poisson,\n",
    "                                 y_bernoulli, y_gamma, y_zig,ss=0,bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted vs observed variance\n",
    "fig_var = uplot.plotSampleVarm(Y_const,y_poisson, y_bernoulli, y_gamma,\n",
    "                               y_zig,hd_const,ss=0,bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted vs empirical cdf\n",
    "nid = 1;\n",
    "fig_cdfslab = uplot.plotCdfSlabm(Y_real, hd_temp, spl_values_poi,spl_values_ber,\n",
    "                   spl_theta_values_zig, zig_k, zig_loc,spl_p_values_zig,\n",
    "                   spl_theta_values_gam, spl_k_values_gam,hd_bins_use,\n",
    "           bin_list=[0,30,60], size=[1,3], nid=nid); #[0,30,60,90,120,150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted tunning curve\n",
    "num=1; \n",
    "nid = 1;\n",
    "tuning_curve = enc.get_tc(Y_train, hd_train, bin_len);\n",
    "tuning_curve2 = enc.get_tc(Y_test, hd_test, bin_len);\n",
    "fig_tc = uplot.plotTC(num, spl_values_poi[:,nid:], \n",
    "                      spl_values_ber[:,nid:], spl_values_gam[:,nid:], spl_values_zig[:,nid:],\n",
    "             tuning_curve[:,nid:],tuning_curve2[:,nid:],bin_len);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted params\n",
    "fig_params=uplot.plotParams([spl_values_poi, spl_theta_values_zig, spl_p_values_zig],\n",
    "                 ['Mean $\\mathbf{\\lambda}$','Scale $\\mathbf{a}$', 'Non-zero prob $\\mathbf{p}$'], bin_len);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute decoding mean absolute error\n",
    "\n",
    "_,poi_error = dec.error(poi_mean_decode[:], hd_const[:]);\n",
    "_,ber_error = dec.error(ber_mean_decode[:], hd_const[:]);\n",
    "_,zig_error = dec.error(zig_mean_decode[:], hd_const[:]);\n",
    "_,gam_error = dec.error(gam_mean_decode[:], hd_const[:]);\n",
    "\n",
    "# training error\n",
    "print('training error: poisson:', np.round(np.abs(poi_error[:nTrain]).sum()/nTrain,2),\n",
    "      'bernoulli:', np.round(np.abs(ber_error[:nTrain]).sum()/nTrain,2),\n",
    "      'gamma:', np.round(np.abs(gam_error[:nTrain]).sum()/nTrain,2),\n",
    "      'zig:', np.round(np.abs(zig_error[:nTrain]).sum()/nTrain,2))\n",
    "\n",
    "# test error\n",
    "print('test error: poisson:', np.round(np.abs(poi_error[(nTrain+nValid):]).sum()/nTest,2),\n",
    "      'bernoulli:', np.round(np.abs(ber_error[(nTrain+nValid):]).sum()/nTest,2),\n",
    "      'gamma:', np.round(np.abs(gam_error[(nTrain+nValid):]).sum()/nTest,2),\n",
    "      'zig:', np.round(np.abs(zig_error[(nTrain+nValid):]).sum()/nTest,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute CI coverage rate when varying multiple confidence levels (this can be slow)\n",
    "width_med_ci, width_mean_ci, conf_rate_ci = dec.getVaryCI(Y_const, hd_const, hd_bins_use, \n",
    "                                                          zig_lik_mat, poi_lik_mat,\n",
    "                                                          ber_lik_mat, gam_lik_mat,\n",
    "                                                          poi_mean_decode,ber_mean_decode, \n",
    "                                                          zig_mean_decode, gam_mean_decode,\n",
    "                                                          nTrain, nValid,nTest);\n",
    "# results are in order zig, poisson, bernoulli, gamma\n",
    "# if only want to compute CI for zig model, please refer to the getVaryCI function in decoding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot log posterior likelihood trace\n",
    "# resemble the data in time order\n",
    "xx = np.asarray(np.linspace(0, Y_real.shape[0]-1, Y_real.shape[0]), dtype='int')\n",
    "xx_split = np.array_split(xx, perm.shape[0]);\n",
    "\n",
    "rlt = [];\n",
    "trial_rlt = [];\n",
    "for ii in range(perm.shape[0]):\n",
    "    rlt = rlt + list(xx_split[perm[ii]]);\n",
    "    trial_rlt = trial_rlt + list(np.tile(ii,xx_split[perm[ii]].shape[0]))\n",
    "    \n",
    "order = np.argsort(rlt);\n",
    "trial_order = np.array(trial_rlt)[order];\n",
    "\n",
    "poi_decode_all = poi_mean_decode[order];\n",
    "zig_decode_all = zig_mean_decode[order];\n",
    "ber_decode_all = ber_mean_decode[order];\n",
    "gam_decode_all = gam_mean_decode[order];\n",
    "\n",
    "poi_lik_all = poi_lik_mat[order];\n",
    "zig_lik_all = zig_lik_mat[order];\n",
    "ber_lik_all = ber_lik_mat[order];\n",
    "gam_lik_all = gam_lik_mat[order];\n",
    "\n",
    "hd_bin_num = uplot.getBinNum(hd, hd_bins_use);\n",
    "poi_bin_num = uplot.getBinNum(poi_decode_all, hd_bins_use);\n",
    "ber_bin_num = uplot.getBinNum(ber_decode_all, hd_bins_use);\n",
    "gam_bin_num = uplot.getBinNum(gam_decode_all, hd_bins_use);\n",
    "zig_bin_num = uplot.getBinNum(zig_decode_all, hd_bins_use);\n",
    "\n",
    "s_te=2000;\n",
    "e_te=5000;\n",
    "\n",
    "poi_temp = np.clip(np.log(poi_lik_all/poi_lik_all.max(axis=1,keepdims=True)),-10,0);\n",
    "ber_temp = np.clip(np.log(ber_lik_all/ber_lik_all.max(axis=1,keepdims=True)),-10,0);\n",
    "gam_temp = np.clip(np.log(gam_lik_all/gam_lik_all.max(axis=1,keepdims=True)),-10,0);\n",
    "zig_temp = np.clip(np.log(zig_lik_all/zig_lik_all.max(axis=1,keepdims=True)),-10,0);\n",
    "\n",
    "fig_conf = uplot.plotHDSuper3(hd_bin_num[s_te:e_te], zig_temp[s_te:e_te].T);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot CI converage rate vs confidence levels and CI converage rate vs CI width\n",
    "conf_level_list=np.array(list(np.linspace(0.9,0.999,10))[:-1] + [1-1e-2, 1-5e-3, 1-1e-3]);\n",
    "print(conf_level_list);\n",
    "\n",
    "fig_cimr = uplot.plotCIcov_mean(conf_rate_ci, width_mean_ci,drop=True);\n",
    "fig_cilr = uplot.plotCIcov_lev(-np.log10(1-conf_rate_ci), -np.log10(1-conf_level_list),real=True,drop=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save results\n",
    "encoding_results = {'poi':[spl_values_poi,yfit_poi,cost_poi,test_cost_poi],'ber':[spl_values_ber, yfit_ber, cost_ber, test_cost_ber],\n",
    "                    'zig':[spl_values_zig, spl_p_values_zig, spl_theta_values_zig, zig_k, zig_loc, yfit_zig, zig_p, zig_theta, cost_zig, test_cost_zig],\n",
    "                    'gam':[spl_values_gam,spl_k_values_gam,spl_theta_values_gam,yfit_gam,gam_k,gam_theta,cost_gam,test_cost_gam]};\n",
    "\n",
    "decoding_results = {'poi':[poi_mean_decode,poi_decode,poi_lik_mat],'ber':[ber_mean_decode,ber_decode,ber_lik_mat],\n",
    "                    'zig':[zig_mean_decode,zig_decode,zig_lik_mat],'gam':[gam_mean_decode,gam_decode,gam_lik_mat],\n",
    "                    'stats':[width_med_ci,width_mean_ci,conf_rate_ci]};\n",
    "\n",
    "np.savez(path+'rlts.npz',encoding_results,decoding_results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
