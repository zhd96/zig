{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load packages\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as ss\n",
    "import sys\n",
    "sys.path.append('../code/');\n",
    "\n",
    "import encoding as enc\n",
    "import decoding as dec\n",
    "import util_plot as uplot\n",
    "\n",
    "seed = 888;\n",
    "np.random.seed(seed) # fix randomness\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deconvolution in matlab (skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load(\"../data/simulated/sim_3stim_vnb_vary_snr.mat\");\n",
    "shape = size(noisy_cal);\n",
    "K = shape(2);\n",
    "T = shape(1);\n",
    "cd = zeros(K,T);\n",
    "s = zeros(K,T);\n",
    "bs = zeros(K,1);\n",
    "pars = zeros(K,1);\n",
    "sn = zeros(K,1);\n",
    "\n",
    "for n = 1:K\n",
    "    [cd(n,:), s(n,:), options] = deconvolveCa(noisy_cal(:,n), 'foopsi', 'ar1', 'smin', 0, 'optimize_pars', false, 'pars', 0.9438634086810337, 'optimize_b', false, 'b', 0);\n",
    "    bs(n,1) = options.b;\n",
    "    pars(n,1) = options.pars;\n",
    "    sn(n,1) = options.sn;\n",
    "end\n",
    "\n",
    "save(\"../data/simulated/stim_vary_snr_s_0_deconv.mat\", 'cd', 's', 'bs', 'pars', 'sn');\n",
    "clear all;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load deconvolved data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load deconvolved data\n",
    "deconv = sio.loadmat(\"../data/simulated/stim_vnb_vary_snr_s_0_deconv.mat\");\n",
    "hd = sio.loadmat(\"../data/ADN29081-Z_20_10_2018/HD_180_deg_ADN29081-Z_20_10_2018.mat\")['HD_180_deg_total'];\n",
    "frame_map = sio.loadmat(\"../data/ADN29081-Z_20_10_2018/frameMap_ADN29081-Z_20_10_2018.mat\")[\"frameMap\"]\n",
    "Y_real = (deconv[\"s\"]/deconv[\"sn\"]).T;\n",
    "hd = np.tile(hd[0,frame_map[:,0]-1],3);\n",
    "Y_real = Y_real[:,:-7];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## result saving path\n",
    "path = './sim_rlt/';\n",
    "\n",
    "## encoding params\n",
    "n_epochs = 2800; # number of epochs \n",
    "learning_rate = 1e-2; # step size \n",
    "gen_nodes = 30; # number of nodes used in hidden layers\n",
    "\n",
    "thresh = 0; # threshold for bernoulli model\n",
    "# if you use hard-threshold method, use the smin you chose for deconvolution; \n",
    "# if you use soft-threshold (L1) method, you should set this to 0;\n",
    "# if you further process the deconvolved traces (eg. downsample), make sure you set thresh to be\n",
    "#the minimum non-zero number minus some small number (eg. 1e-6).\n",
    "gam_shift = 1e-4; # shift for gamma model, in general take it as a small number\n",
    "factor = np.ones(Y_real.shape[1])*thresh; # location parameter for SNG model\n",
    "\n",
    "## decoding params\n",
    "bin_len = 181; # number of bins used for bayesian decoding analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = 11153*3;\n",
    "nValid = 3584*3;\n",
    "nTest = Y_real.shape[0]-nTrain-nValid;\n",
    "\n",
    "Y_train = Y_real[:nTrain,:];\n",
    "Y_valid = Y_real[nTrain:(nTrain+nValid),:];\n",
    "Y_test = Y_real[(nTrain+nValid):,:];\n",
    "\n",
    "hd_train = hd[:nTrain];\n",
    "hd_valid = hd[nTrain:(nTrain+nValid)];\n",
    "hd_test = hd[(nTrain+nValid):];\n",
    "\n",
    "Y_const = Y_real;\n",
    "hd_const = hd;\n",
    "\n",
    "hd_bins_use = np.linspace(-180,180,bin_len)[1:];\n",
    "hd_temp = uplot.getBins(hd, hd_bins_use);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train encoding models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## poisson\n",
    "spl_values_poi,yfit_poi,cost_poi,test_cost_poi=enc.poissonRunner(Y_train,Y_valid,hd_train,hd_valid,hd_test,n_epochs=n_epochs,learning_rate=learning_rate,gen_nodes=gen_nodes,bin_len=bin_len,path=path);\n",
    "\n",
    "## bernoulli\n",
    "spl_values_ber, yfit_ber, cost_ber, test_cost_ber = enc.bernoulliRunner(Y_train,Y_valid,hd_train,hd_valid,hd_test, thresh=thresh,n_epochs=n_epochs,learning_rate=learning_rate,gen_nodes=gen_nodes,bin_len=bin_len,path=path);\n",
    "\n",
    "## gamma\n",
    "spl_values_gam,spl_k_values_gam,spl_theta_values_gam,yfit_gam,gam_k,gam_theta,cost_gam,test_cost_gam=enc.gammaRunner(Y_train,Y_valid,hd_train,hd_valid,hd_test,factor=gam_shift,n_epochs=n_epochs,learning_rate=learning_rate,gen_nodes=gen_nodes,bin_len=bin_len,path=path);\n",
    "\n",
    "## sng\n",
    "spl_values_zig, spl_p_values_zig, spl_theta_values_zig, zig_k, zig_loc, yfit_zig, zig_p, zig_theta, cost_zig, test_cost_zig = enc.sngRlxRunner(Y_train, Y_valid, hd_train,hd_valid, hd_test, factor, n_epochs=n_epochs,learning_rate=5e-3, gen_nodes=gen_nodes,bin_len=bin_len,path=path);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bayesian decoding analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## poisson\n",
    "poi_mean_decode, poi_decode, poi_lik_mat = dec.poissonDecoding(Y_const, spl_values_poi, bin_len=bin_len);\n",
    "\n",
    "## bernoulli\n",
    "ber_mean_decode, ber_decode, ber_lik_mat = dec.bernoulliDecoding(Y_const, thresh, spl_values_ber, bin_len=bin_len);\n",
    "\n",
    "## gamma\n",
    "gam_mean_decode,gam_decode,gam_lik_mat=dec.gammaDecoding(Y_const,spl_k_values_gam,spl_theta_values_gam,factor=gam_shift,bin_len=bin_len);\n",
    "\n",
    "## SNG\n",
    "zig_mean_decode, zig_decode, zig_lik_mat = dec.sngRlxDecoding(Y_const, spl_theta_values_zig, \n",
    "                                                           spl_p_values_zig, zig_k, zig_loc, bin_len=bin_len);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check encoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sample data\n",
    "y_poisson, p_poi = enc.samplePoisson(yfit_poi, seed=seed);\n",
    "y_bernoulli = enc.sampleBernoulli(yfit_ber, seed=seed);\n",
    "y_zig = enc.sampleSngRlx(zig_p, zig_k, zig_theta, zig_loc, seed=seed);\n",
    "y_gamma = enc.sampleGamma(gam_k, gam_theta, seed=seed);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## diagnostic plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted vs observed mean\n",
    "fig_rate = uplot.plotSampleRatem(Y_const, hd_const, y_poisson,\n",
    "                                 y_bernoulli, y_gamma, y_zig,ss=0,bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted vs observed variance\n",
    "fig_var = uplot.plotSampleVarm(Y_const,y_poisson, y_bernoulli, y_gamma,\n",
    "                               y_zig,hd_const,ss=0,bins=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted vs empirical cdf\n",
    "nid = 1;\n",
    "fig_cdfslab = uplot.plotCdfSlabm(Y_real, hd_temp, spl_values_poi,spl_values_ber,\n",
    "                   spl_theta_values_zig, zig_k, zig_loc,spl_p_values_zig,\n",
    "                   spl_theta_values_gam, spl_k_values_gam,hd_bins_use,\n",
    "           bin_list=[0,30,60], size=[1,3], nid=nid); #[0,30,60,90,120,150]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted tunning curve\n",
    "num=1; \n",
    "nid = 1;\n",
    "tuning_curve = enc.get_tc(Y_train, hd_train, bin_len);\n",
    "tuning_curve2 = enc.get_tc(Y_test, hd_test, bin_len);\n",
    "fig_tc = uplot.plotTC(num, spl_values_poi[:,nid:], \n",
    "                      spl_values_ber[:,nid:], spl_values_gam[:,nid:], spl_values_zig[:,nid:],\n",
    "             tuning_curve[:,nid:],tuning_curve2[:,nid:],bin_len);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot fitted params\n",
    "fig_params=uplot.plotParams([spl_values_poi, spl_theta_values_zig, spl_p_values_zig],\n",
    "                 ['Mean $\\mathbf{\\lambda}$','Scale $\\mathbf{a}$', 'Non-zero prob $\\mathbf{p}$'], bin_len);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check decoding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute decoding mean absolute error\n",
    "\n",
    "_,poi_error = dec.error(poi_mean_decode[:], hd_const[:]);\n",
    "_,ber_error = dec.error(ber_mean_decode[:], hd_const[:]);\n",
    "_,zig_error = dec.error(zig_mean_decode[:], hd_const[:]);\n",
    "_,gam_error = dec.error(gam_mean_decode[:], hd_const[:]);\n",
    "\n",
    "# training error\n",
    "print('training error: poisson:', np.round(np.abs(poi_error[:nTrain]).sum()/nTrain,2),\n",
    "      'bernoulli:', np.round(np.abs(ber_error[:nTrain]).sum()/nTrain,2),\n",
    "      'gamma:', np.round(np.abs(gam_error[:nTrain]).sum()/nTrain,2),\n",
    "      'SNG:', np.round(np.abs(zig_error[:nTrain]).sum()/nTrain,2))\n",
    "\n",
    "# test error\n",
    "print('test error: poisson:', np.round(np.abs(poi_error[(nTrain+nValid):]).sum()/nTest,2),\n",
    "      'bernoulli:', np.round(np.abs(ber_error[(nTrain+nValid):]).sum()/nTest,2),\n",
    "      'gamma:', np.round(np.abs(gam_error[(nTrain+nValid):]).sum()/nTest,2),\n",
    "      'SNG:', np.round(np.abs(zig_error[(nTrain+nValid):]).sum()/nTest,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute CI coverage rate when varying multiple confidence levels (this can be slow)\n",
    "width_med_ci, width_mean_ci, conf_rate_ci = dec.getVaryCI(Y_const, hd_const, hd_bins_use, \n",
    "                                                          zig_lik_mat, poi_lik_mat,\n",
    "                                                          ber_lik_mat, gam_lik_mat,\n",
    "                                                          poi_mean_decode,ber_mean_decode, \n",
    "                                                          zig_mean_decode, gam_mean_decode,\n",
    "                                                          nTrain, nValid,nTest);\n",
    "# results are in order SNG, poisson, bernoulli, gamma\n",
    "# if only want to compute CI for SNG model, please refer to the getVaryCI function in decoding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot log posterior likelihood trace\n",
    "hd_bin_num = uplot.getBinNum(hd, hd_bins_use);\n",
    "poi_bin_num = uplot.getBinNum(poi_mean_decode, hd_bins_use);\n",
    "ber_bin_num = uplot.getBinNum(ber_mean_decode, hd_bins_use);\n",
    "gam_bin_num = uplot.getBinNum(gam_mean_decode, hd_bins_use);\n",
    "zig_bin_num = uplot.getBinNum(zig_mean_decode, hd_bins_use);\n",
    "\n",
    "poi_temp = np.clip(np.log(poi_lik_mat/poi_lik_mat.max(axis=1,keepdims=True)),-10,0);\n",
    "ber_temp = np.clip(np.log(ber_lik_mat/ber_lik_mat.max(axis=1,keepdims=True)),-10,0);\n",
    "gam_temp = np.clip(np.log(gam_lik_mat/gam_lik_mat.max(axis=1,keepdims=True)),-10,0);\n",
    "zig_temp = np.clip(np.log(zig_lik_mat/zig_lik_mat.max(axis=1,keepdims=True)),-10,0);\n",
    "\n",
    "s_tr=nTrain-1000-1500;\n",
    "e_tr=s_tr+1500;\n",
    "\n",
    "s_te=nTrain+nValid+1500;\n",
    "e_te=s_te+1500;\n",
    "select=np.array(list(np.arange(s_tr,e_tr))+list(np.arange(s_te,e_te)))\n",
    "\n",
    "fig_conf = uplot.plotHDSuper3(hd_bin_num[select], zig_temp[select].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot CI converage rate vs confidence levels and CI converage rate vs CI width\n",
    "conf_level_list=np.array(list(np.linspace(0.9,0.999,10))[:-1] + [1-1e-2, 1-5e-3, 1-1e-3]);\n",
    "print(conf_level_list);\n",
    "\n",
    "fig_cimr = uplot.plotCIcov_mean(conf_rate_ci, width_mean_ci,drop=False);\n",
    "fig_cilr = uplot.plotCIcov_lev(-np.log10(1-conf_rate_ci), -np.log10(1-conf_level_list),real=False,drop=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save results\n",
    "encoding_results = {'poi':[spl_values_poi,yfit_poi,cost_poi,test_cost_poi],'ber':[spl_values_ber, yfit_ber, cost_ber, test_cost_ber],\n",
    "                    'zig':[spl_values_zig, spl_p_values_zig, spl_theta_values_zig, zig_k, zig_loc, yfit_zig, zig_p, zig_theta, cost_zig, test_cost_zig],\n",
    "                    'gam':[spl_values_gam,spl_k_values_gam,spl_theta_values_gam,yfit_gam,gam_k,gam_theta,cost_gam,test_cost_gam]};\n",
    "\n",
    "decoding_results = {'poi':[poi_mean_decode,poi_decode,poi_lik_mat],'ber':[ber_mean_decode,ber_decode,ber_lik_mat],\n",
    "                    'zig':[zig_mean_decode,zig_decode,zig_lik_mat],'gam':[gam_mean_decode,gam_decode,gam_lik_mat],\n",
    "                    'stats':[width_med_ci,width_mean_ci,conf_rate_ci]};\n",
    "\n",
    "np.savez(path+'rlts.npz',encoding_results,decoding_results);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
